{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "## SVM Implementation with TensowFlow\n - Reference: This work is based on material provided in the book: TensorFlow Machine Learning Cookbook by Nick McClure"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nfrom sklearn.datasets import (load_breast_cancer, load_iris)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np",
      "execution_count": 54,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Define helper logic"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class ProblemProvider(object):\n    def __init__(self):\n        self._problem_store = {}\n        self._X_train, self._X_test, self._y_train, self._y_test = None, None, None, None\n        self._scaled_X_train, self._scaled_X_test = None, None\n        self.setProblemData()\n            \n    def setCancerData(self):\n        cancer_data = load_breast_cancer()\n        X = cancer_data.data\n        y = cancer_data.target\n        y = np.reshape(y, (y.shape[0], 1))\n        self._X_train, self._X_test, self._y_train, self._y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n        self.rescaleData()\n        \n    def setIrisData(self):\n        iris_data = load_iris()\n        X = np.array([[x[0], x[3]] for x in iris_data.data])\n        y = np.array([1 if y == 0 else -1 for y in iris_data.target])\n        y = np.reshape(y, (y.shape[0], 1))\n        self._X_train, self._X_test, self._y_train, self._y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n        self.rescaleData()\n        \n    def setProblemData(self):\n        data_sets = {'Cancer_Data': self.setCancerData, 'Iris_Data': self.setIrisData}\n        for data_set in data_sets:\n            data_sets[data_set]()\n            self._problem_store[data_set] = {\n                                    'Scaler': self._scaler,\n                                    'X_train_scaled':  self._X_train_scaled,\n                                    \"X_test_scaled\": self._X_test_scaled,\n                                    \"y_train\": self._y_train,\n                                    \"y_test\": self._y_test\n                                        }\n\n    def rescaleData(self):\n        self._scaler = StandardScaler()\n        self._X_train_scaled = self._scaler.fit_transform(self._X_train)\n        self._X_test_scaled = self._scaler.fit_transform(self._X_test)\n    ",
      "execution_count": 71,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "problem_provider = ProblemProvider()\ncancer_problem_prov = problem_provider._problem_store['Iris_Data']\nscaler = cancer_problem_prov['Scaler']\nX_train = cancer_problem_prov['X_train_scaled']\nX_test = cancer_problem_prov['X_test_scaled']\ny_train = cancer_problem_prov['y_train']\ny_test = cancer_problem_prov['y_test']\n",
      "execution_count": 74,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train[:5,:]",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 75,
          "data": {
            "text/plain": "array([[-0.13835603,  0.11008189],\n       [ 2.14752625,  1.18405156],\n       [-0.25866563,  0.37857431],\n       [-0.8602136 , -1.36662641],\n       [ 2.26783585,  1.04980535]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Specify the SVM using Tensorflow constructs"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class SvmUsingTensorflow(object):\n    def __init__(self, X_train, y_train):\n        # Define the Tensorflow session\n        self._sess = tf.Session()\n        \n        # Define number of iteration to start reporting updates\n        self._reported_iteration = 100\n        \n        # Define the training feature dataset\n        self._X_train = X_train\n        \n        # Define the training target vector\n        self._y_train = y_train\n        \n        # Define the number of training samples/features\n        self._n_samples = self._X_train.shape[0]\n        self._n_features = float(self._X_train.shape[1])\n        \n        # Declare batch size\n        self._batch_size = 150\n        \n        # Declare the Guassain Kernel 'gamma' parameter\n        self._gamma_param = -25\n        \n        # Define learning rate\n        self._learn_rate = 0.01\n\n        # Initialize placeholders\n        self._x_data = tf.placeholder(shape=[None, self._n_features], dtype=tf.float32)\n        self._y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n        self._prediction_grid = tf.placeholder(shape=[None, self._n_features], dtype=tf.float32)\n        \n        # Create variables for svm\n        self._b = tf.Variable(tf.random_normal(shape=[1, batch_size]))\n        \n        # Define the feature/prediction kernelss\n        self._feature_kernel = self.computeLinearFeatureKernel()\n        self._predict_kernel = self.computeLinearPredictionKernel()\n        \n        # Define the loss function\n        self._loss = self.computeLoss()\n        \n        # Define the model Accuracy\n        self._accuracy = self.computeAccuracy()\n        \n        # Define the Trainer\n        self._train_step = self.computeTrainer()\n        \n        # Initialize variables\n        init = tf.global_variables_initializer()\n        self._sess.run(init)\n        \n    \n    def computeLinearFeatureKernel(self):\n        sq_dists = tf.matmul(self._x_data, tf.transpose(self._x_data))\n        return sq_dists    \n    \n    def computeGuassainFeatureKernel(self):\n        gamma = tf.constant(self._gamma_param)\n        sq_dists = tf.multiply(self._n_features, tf.matmul(self._x_data, tf.transpose(self._x_data)))\n        return tf.exp(tf.multiply(gamma, tf.abs(sq_dists)))\n    \n    def computeLinearPredictionKernel(self):\n        sq_dists = tf.matmul(self._x_data, tf.transpose(self._prediction_grid))\n        return sq_dists    \n    \n    def computeGuassainPredictionKernel(self):\n        gamma = tf.constant(self._gamma_param)\n        rA = tf.reshape(tf.reduce_sum(tf.square(self._x_data), 1), [-1, 1])\n        rB = tf.reshape(tf.reduce_sum(tf.square(self._prediction_grid), 1), [-1, 1])\n        pred_sq_dist = tf.add(tf.subtract(rA, tf.multiply(self._n_features, tf.matmul(self._x_data, tf.transpose(self._prediction_grid)))), tf.transpose(rB))\n        pred_kernel = tf.exp(tf.multiply(gamma, tf.abs(pred_sq_dist)))\n        \n    def computeLoss(self):        \n        first_term = tf.reduce_sum(self._b)\n        b_vec_cross = tf.matmul(tf.transpose(self._b), self._b)\n        y_target_cross = tf.matmul(self._y_target, tf.transpose(self._y_target))\n        second_term = tf.reduce_sum(tf.multiply(self._feature_kernel, tf.multiply(b_vec_cross, y_target_cross)))\n        loss = tf.negative(tf.subtract(first_term, second_term))\n        return loss\n    \n    def computeAccuracy(self):\n        prediction_output = tf.matmul(tf.multiply(tf.transpose(self._y_target), b), self._predict_kernel)\n        prediction = tf.sign(prediction_output - tf.reduce_mean(prediction_output))\n        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.squeeze(prediction), tf.squeeze(self._y_target)), tf.float32))\n        return accuracy\n    \n    def computeTrainer(self):\n        optimizer = tf.train.GradientDescentOptimizer(self._learn_rate)\n        train_step = optimizer.minimize(self._loss)\n        \n    def updateStatus(self, i, loss_i):\n        if (i + 1) % self._reported_iteration == 0:\n            print('Step # {0}'.format(i + 1))\n            print('Loss = {}'.format(loss_i))\n        \n    def runMainLoop(self, epochs=300):\n        loss_vec = []\n        batch_accuracy = []\n        for i in range(epochs):\n            rand_index = np.random.choice(len(self._X_train), size=self._batch_size)\n            rand_x = x_vals[rand_index]\n            rand_y = np.transpose([self._y_train[rand_index]])\n            sess.run(self._train_step, feed_dict={self._x_data: rand_x, self._y_target: rand_y})\n\n            loss_i = sess.run(self._loss, feed_dict={self._x_data: rand_x, self._y_target: rand_y})\n            loss_vec.append(loss_i)\n\n            accuracy_i = sess.run(accuracy, feed_dict={self._x_data: rand_x,\n                                                     self._y_target: rand_y,\n                                                     self._prediction_grid: rand_x})\n            batch_accuracy.append(accuracy_i)\n            self.updateStatus(i, loss_i)\n\n        \n    \n        \n        ",
      "execution_count": 47,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/plain": "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n       0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}