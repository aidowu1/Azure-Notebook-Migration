{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Simple first attempt at predicting price direction using a shallow MLP Neural Net"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport keras.models as km\nimport keras.layers as kl\nimport sklearn.preprocessing as spp\nimport sklearn.model_selection as smo",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#stock_market_data = np.loadtxt(\"Data\\S_Market_Data_ISRL.csv\", delimiter=\",\")\nstock_market_data_table = pd.read_csv(\"data/S_Market_Data_ISRL.csv\", sep=\",\",index_col=0)\ncols = stock_market_data_table.columns.values.tolist()\nn_cols = len(cols) - 1\nstock_market_data_table.Direction = stock_market_data_table.Direction.apply(lambda x: 1 if x == 'Up' else 0) \nstock_market_data_table.head()",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "   Year   Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today  Direction\n1  2001  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959          1\n2  2001  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032          1\n3  2001  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623          0\n4  2001 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614          1\n5  2001  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213          1",
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Lag1</th>\n      <th>Lag2</th>\n      <th>Lag3</th>\n      <th>Lag4</th>\n      <th>Lag5</th>\n      <th>Volume</th>\n      <th>Today</th>\n      <th>Direction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2001</td>\n      <td>0.381</td>\n      <td>-0.192</td>\n      <td>-2.624</td>\n      <td>-1.055</td>\n      <td>5.010</td>\n      <td>1.1913</td>\n      <td>0.959</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2001</td>\n      <td>0.959</td>\n      <td>0.381</td>\n      <td>-0.192</td>\n      <td>-2.624</td>\n      <td>-1.055</td>\n      <td>1.2965</td>\n      <td>1.032</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2001</td>\n      <td>1.032</td>\n      <td>0.959</td>\n      <td>0.381</td>\n      <td>-0.192</td>\n      <td>-2.624</td>\n      <td>1.4112</td>\n      <td>-0.623</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2001</td>\n      <td>-0.623</td>\n      <td>1.032</td>\n      <td>0.959</td>\n      <td>0.381</td>\n      <td>-0.192</td>\n      <td>1.2760</td>\n      <td>0.614</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2001</td>\n      <td>0.614</td>\n      <td>-0.623</td>\n      <td>1.032</td>\n      <td>0.959</td>\n      <td>0.381</td>\n      <td>1.2057</td>\n      <td>0.213</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "stock_market_data_table.describe()",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "              Year         Lag1         Lag2         Lag3         Lag4  \\\ncount  1250.000000  1250.000000  1250.000000  1250.000000  1250.000000   \nmean   2003.016000     0.003834     0.003919     0.001716     0.001636   \nstd       1.409018     1.136299     1.136280     1.138703     1.138774   \nmin    2001.000000    -4.922000    -4.922000    -4.922000    -4.922000   \n25%    2002.000000    -0.639500    -0.639500    -0.640000    -0.640000   \n50%    2003.000000     0.039000     0.039000     0.038500     0.038500   \n75%    2004.000000     0.596750     0.596750     0.596750     0.596750   \nmax    2005.000000     5.733000     5.733000     5.733000     5.733000   \n\n             Lag5       Volume        Today    Direction  \ncount  1250.00000  1250.000000  1250.000000  1250.000000  \nmean      0.00561     1.478305     0.003138     0.518400  \nstd       1.14755     0.360357     1.136334     0.499861  \nmin      -4.92200     0.356070    -4.922000     0.000000  \n25%      -0.64000     1.257400    -0.639500     0.000000  \n50%       0.03850     1.422950     0.038500     1.000000  \n75%       0.59700     1.641675     0.596750     1.000000  \nmax       5.73300     3.152470     5.733000     1.000000  ",
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Lag1</th>\n      <th>Lag2</th>\n      <th>Lag3</th>\n      <th>Lag4</th>\n      <th>Lag5</th>\n      <th>Volume</th>\n      <th>Today</th>\n      <th>Direction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1250.000000</td>\n      <td>1250.000000</td>\n      <td>1250.000000</td>\n      <td>1250.000000</td>\n      <td>1250.000000</td>\n      <td>1250.00000</td>\n      <td>1250.000000</td>\n      <td>1250.000000</td>\n      <td>1250.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2003.016000</td>\n      <td>0.003834</td>\n      <td>0.003919</td>\n      <td>0.001716</td>\n      <td>0.001636</td>\n      <td>0.00561</td>\n      <td>1.478305</td>\n      <td>0.003138</td>\n      <td>0.518400</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.409018</td>\n      <td>1.136299</td>\n      <td>1.136280</td>\n      <td>1.138703</td>\n      <td>1.138774</td>\n      <td>1.14755</td>\n      <td>0.360357</td>\n      <td>1.136334</td>\n      <td>0.499861</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2001.000000</td>\n      <td>-4.922000</td>\n      <td>-4.922000</td>\n      <td>-4.922000</td>\n      <td>-4.922000</td>\n      <td>-4.92200</td>\n      <td>0.356070</td>\n      <td>-4.922000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2002.000000</td>\n      <td>-0.639500</td>\n      <td>-0.639500</td>\n      <td>-0.640000</td>\n      <td>-0.640000</td>\n      <td>-0.64000</td>\n      <td>1.257400</td>\n      <td>-0.639500</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2003.000000</td>\n      <td>0.039000</td>\n      <td>0.039000</td>\n      <td>0.038500</td>\n      <td>0.038500</td>\n      <td>0.03850</td>\n      <td>1.422950</td>\n      <td>0.038500</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2004.000000</td>\n      <td>0.596750</td>\n      <td>0.596750</td>\n      <td>0.596750</td>\n      <td>0.596750</td>\n      <td>0.59700</td>\n      <td>1.641675</td>\n      <td>0.596750</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2005.000000</td>\n      <td>5.733000</td>\n      <td>5.733000</td>\n      <td>5.733000</td>\n      <td>5.733000</td>\n      <td>5.73300</td>\n      <td>3.152470</td>\n      <td>5.733000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "stock_market_data_table.count()",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "Year         1250\nLag1         1250\nLag2         1250\nLag3         1250\nLag4         1250\nLag5         1250\nVolume       1250\nToday        1250\nDirection    1250\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "stock_market_data_table.columns = range(len(stock_market_data_table.columns))\nstock_market_data = stock_market_data_table.as_matrix()\n# #split into input (X) and output (Y) variables\nX = stock_market_data[:,0:n_cols]\ny = stock_market_data[:,n_cols]",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "scaler = spp.StandardScaler()\nX_scaled = scaler.fit_transform(X)",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_scale_train, X_scale_test, y_train, y_test = smo.train_test_split(X_scaled, y, test_size=0.3, random_state=10)",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model = km.Sequential()",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.add(kl.Dense(20, input_dim=n_cols, activation='relu'))\nmodel.add(kl.Dense(10, activation='relu'))\nmodel.add(kl.Dense(1, activation='sigmoid'))",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Visualize the Network"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def visualizeNetwork(model):\n    from IPython.display import SVG\n    from keras.utils.vis_utils import model_to_dot\n    SVG(model_to_dot(model).create(prog='dot', format='svg'))\n\n#visualizeNetwork(model)",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Compile model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# Fit the model\nmodel.fit(X_scale_train, y_train, epochs=150, batch_size=10)\n",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1/150\n875/875 [==============================] - 1s - loss: 0.7001 - acc: 0.5029     \nEpoch 2/150\n875/875 [==============================] - 0s - loss: 0.5960 - acc: 0.7623     \nEpoch 3/150\n875/875 [==============================] - 0s - loss: 0.4608 - acc: 0.8731     \nEpoch 4/150\n875/875 [==============================] - 0s - loss: 0.3277 - acc: 0.9154     \nEpoch 5/150\n875/875 [==============================] - 0s - loss: 0.2274 - acc: 0.9417     \nEpoch 6/150\n875/875 [==============================] - 0s - loss: 0.1663 - acc: 0.9737     \nEpoch 7/150\n875/875 [==============================] - 0s - loss: 0.1279 - acc: 0.9749     \nEpoch 8/150\n875/875 [==============================] - 0s - loss: 0.1048 - acc: 0.9783     \nEpoch 9/150\n875/875 [==============================] - 0s - loss: 0.0862 - acc: 0.9817     \nEpoch 10/150\n875/875 [==============================] - 0s - loss: 0.0758 - acc: 0.9840     \nEpoch 11/150\n875/875 [==============================] - 0s - loss: 0.0666 - acc: 0.9886     \nEpoch 12/150\n875/875 [==============================] - 0s - loss: 0.0587 - acc: 0.9897     \nEpoch 13/150\n875/875 [==============================] - 0s - loss: 0.0525 - acc: 0.9943     \nEpoch 14/150\n875/875 [==============================] - 0s - loss: 0.0485 - acc: 0.9943     \nEpoch 15/150\n875/875 [==============================] - 0s - loss: 0.0439 - acc: 0.9920     \nEpoch 16/150\n875/875 [==============================] - 0s - loss: 0.0407 - acc: 0.9931     \nEpoch 17/150\n875/875 [==============================] - 0s - loss: 0.0380 - acc: 0.9943     \nEpoch 18/150\n875/875 [==============================] - 0s - loss: 0.0353 - acc: 0.9954     \nEpoch 19/150\n875/875 [==============================] - 0s - loss: 0.0328 - acc: 0.9954     \nEpoch 20/150\n875/875 [==============================] - 0s - loss: 0.0307 - acc: 0.9966     \nEpoch 21/150\n875/875 [==============================] - 0s - loss: 0.0286 - acc: 0.9954     \nEpoch 22/150\n875/875 [==============================] - 0s - loss: 0.0265 - acc: 0.9966     \nEpoch 23/150\n875/875 [==============================] - 0s - loss: 0.0261 - acc: 0.9966     \nEpoch 24/150\n875/875 [==============================] - 0s - loss: 0.0241 - acc: 0.9977     \nEpoch 25/150\n875/875 [==============================] - 0s - loss: 0.0216 - acc: 0.9989     \nEpoch 26/150\n875/875 [==============================] - 0s - loss: 0.0209 - acc: 0.9977     \nEpoch 27/150\n875/875 [==============================] - 0s - loss: 0.0198 - acc: 0.9977       \nEpoch 28/150\n875/875 [==============================] - 0s - loss: 0.0182 - acc: 0.9977       \nEpoch 29/150\n875/875 [==============================] - 0s - loss: 0.0170 - acc: 0.9989       \nEpoch 30/150\n875/875 [==============================] - 0s - loss: 0.0165 - acc: 0.9977     \nEpoch 31/150\n875/875 [==============================] - 0s - loss: 0.0155 - acc: 0.9989     \nEpoch 32/150\n875/875 [==============================] - 0s - loss: 0.0153 - acc: 0.9989     \nEpoch 33/150\n875/875 [==============================] - 0s - loss: 0.0137 - acc: 0.9989     \nEpoch 34/150\n875/875 [==============================] - 0s - loss: 0.0134 - acc: 0.9989     \nEpoch 35/150\n875/875 [==============================] - 0s - loss: 0.0125 - acc: 0.9989     \nEpoch 36/150\n875/875 [==============================] - 0s - loss: 0.0115 - acc: 0.9989     \nEpoch 37/150\n875/875 [==============================] - 0s - loss: 0.0107 - acc: 0.9989     \nEpoch 38/150\n875/875 [==============================] - 0s - loss: 0.0103 - acc: 1.0000       \nEpoch 39/150\n875/875 [==============================] - 0s - loss: 0.0095 - acc: 0.9989     \nEpoch 40/150\n875/875 [==============================] - 0s - loss: 0.0088 - acc: 1.0000     \nEpoch 41/150\n875/875 [==============================] - 0s - loss: 0.0084 - acc: 1.0000       \nEpoch 42/150\n875/875 [==============================] - 0s - loss: 0.0076 - acc: 1.0000       \nEpoch 43/150\n875/875 [==============================] - 0s - loss: 0.0078 - acc: 1.0000     \nEpoch 44/150\n875/875 [==============================] - 0s - loss: 0.0067 - acc: 1.0000     \nEpoch 45/150\n875/875 [==============================] - 0s - loss: 0.0065 - acc: 1.0000     \nEpoch 46/150\n875/875 [==============================] - 0s - loss: 0.0067 - acc: 1.0000       \nEpoch 47/150\n875/875 [==============================] - 0s - loss: 0.0057 - acc: 1.0000       \nEpoch 48/150\n875/875 [==============================] - 0s - loss: 0.0054 - acc: 1.0000     \nEpoch 49/150\n875/875 [==============================] - 0s - loss: 0.0052 - acc: 1.0000     \nEpoch 50/150\n875/875 [==============================] - 0s - loss: 0.0047 - acc: 1.0000     \nEpoch 51/150\n875/875 [==============================] - 0s - loss: 0.0053 - acc: 1.0000     \nEpoch 52/150\n875/875 [==============================] - 0s - loss: 0.0043 - acc: 1.0000       \nEpoch 53/150\n875/875 [==============================] - 0s - loss: 0.0041 - acc: 1.0000       \nEpoch 54/150\n875/875 [==============================] - 0s - loss: 0.0038 - acc: 1.0000       \nEpoch 55/150\n875/875 [==============================] - 0s - loss: 0.0038 - acc: 1.0000     \nEpoch 56/150\n875/875 [==============================] - 0s - loss: 0.0033 - acc: 1.0000     \nEpoch 57/150\n875/875 [==============================] - 0s - loss: 0.0033 - acc: 1.0000     \nEpoch 58/150\n875/875 [==============================] - 0s - loss: 0.0030 - acc: 1.0000       \nEpoch 59/150\n875/875 [==============================] - 0s - loss: 0.0029 - acc: 1.0000     \nEpoch 60/150\n875/875 [==============================] - 0s - loss: 0.0027 - acc: 1.0000     \nEpoch 61/150\n875/875 [==============================] - 0s - loss: 0.0025 - acc: 1.0000     \nEpoch 62/150\n875/875 [==============================] - 0s - loss: 0.0023 - acc: 1.0000     \nEpoch 63/150\n875/875 [==============================] - 0s - loss: 0.0023 - acc: 1.0000       \nEpoch 64/150\n875/875 [==============================] - 0s - loss: 0.0021 - acc: 1.0000       \nEpoch 65/150\n875/875 [==============================] - 0s - loss: 0.0020 - acc: 1.0000       \nEpoch 66/150\n875/875 [==============================] - 0s - loss: 0.0019 - acc: 1.0000     \nEpoch 67/150\n875/875 [==============================] - 0s - loss: 0.0018 - acc: 1.0000     \nEpoch 68/150\n875/875 [==============================] - 0s - loss: 0.0017 - acc: 1.0000     \nEpoch 69/150\n875/875 [==============================] - 0s - loss: 0.0017 - acc: 1.0000        \nEpoch 70/150\n875/875 [==============================] - 0s - loss: 0.0018 - acc: 1.0000     \nEpoch 71/150\n875/875 [==============================] - 0s - loss: 0.0016 - acc: 1.0000       \nEpoch 72/150\n875/875 [==============================] - 0s - loss: 0.0014 - acc: 1.0000       \nEpoch 73/150\n875/875 [==============================] - 0s - loss: 0.0012 - acc: 1.0000       \nEpoch 74/150\n875/875 [==============================] - 0s - loss: 0.0012 - acc: 1.0000       \nEpoch 75/150\n875/875 [==============================] - 0s - loss: 0.0011 - acc: 1.0000        \nEpoch 76/150\n875/875 [==============================] - 0s - loss: 0.0012 - acc: 1.0000     \nEpoch 77/150\n875/875 [==============================] - 0s - loss: 0.0010 - acc: 1.0000         \nEpoch 78/150\n875/875 [==============================] - 0s - loss: 9.9729e-04 - acc: 1.0000     \nEpoch 79/150\n875/875 [==============================] - 0s - loss: 9.3698e-04 - acc: 1.0000     \nEpoch 80/150\n875/875 [==============================] - 0s - loss: 8.7038e-04 - acc: 1.0000     \nEpoch 81/150\n875/875 [==============================] - 0s - loss: 8.0711e-04 - acc: 1.0000     \nEpoch 82/150\n875/875 [==============================] - 0s - loss: 8.1513e-04 - acc: 1.0000     \nEpoch 83/150\n875/875 [==============================] - 0s - loss: 7.1224e-04 - acc: 1.0000     \nEpoch 84/150\n875/875 [==============================] - 0s - loss: 6.6891e-04 - acc: 1.0000     \nEpoch 85/150\n875/875 [==============================] - 0s - loss: 6.3433e-04 - acc: 1.0000     \nEpoch 86/150\n875/875 [==============================] - 0s - loss: 6.0936e-04 - acc: 1.0000     \nEpoch 87/150\n875/875 [==============================] - 0s - loss: 5.6438e-04 - acc: 1.0000     \nEpoch 88/150\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "875/875 [==============================] - 0s - loss: 5.4341e-04 - acc: 1.0000     \nEpoch 89/150\n875/875 [==============================] - 0s - loss: 5.7757e-04 - acc: 1.0000     \nEpoch 90/150\n875/875 [==============================] - 0s - loss: 5.1940e-04 - acc: 1.0000     \nEpoch 91/150\n875/875 [==============================] - 0s - loss: 4.7771e-04 - acc: 1.0000     \nEpoch 92/150\n875/875 [==============================] - 0s - loss: 4.3151e-04 - acc: 1.0000     \nEpoch 93/150\n875/875 [==============================] - 0s - loss: 4.1437e-04 - acc: 1.0000     \nEpoch 94/150\n875/875 [==============================] - 0s - loss: 4.1202e-04 - acc: 1.0000     \nEpoch 95/150\n875/875 [==============================] - 0s - loss: 3.7995e-04 - acc: 1.0000     \nEpoch 96/150\n875/875 [==============================] - 0s - loss: 3.8784e-04 - acc: 1.0000     \nEpoch 97/150\n875/875 [==============================] - 0s - loss: 3.3485e-04 - acc: 1.0000     \nEpoch 98/150\n875/875 [==============================] - 0s - loss: 3.1309e-04 - acc: 1.0000     \nEpoch 99/150\n875/875 [==============================] - 0s - loss: 2.9096e-04 - acc: 1.0000     \nEpoch 100/150\n875/875 [==============================] - 0s - loss: 2.7666e-04 - acc: 1.0000     \nEpoch 101/150\n875/875 [==============================] - 0s - loss: 2.6873e-04 - acc: 1.0000     \nEpoch 102/150\n875/875 [==============================] - 0s - loss: 2.4708e-04 - acc: 1.0000     \nEpoch 103/150\n875/875 [==============================] - 0s - loss: 2.2989e-04 - acc: 1.0000     \nEpoch 104/150\n875/875 [==============================] - 0s - loss: 2.3050e-04 - acc: 1.0000     \nEpoch 105/150\n875/875 [==============================] - 0s - loss: 2.1738e-04 - acc: 1.0000     \nEpoch 106/150\n875/875 [==============================] - 0s - loss: 2.0289e-04 - acc: 1.0000     \nEpoch 107/150\n875/875 [==============================] - 0s - loss: 2.0220e-04 - acc: 1.0000     \nEpoch 108/150\n875/875 [==============================] - 0s - loss: 2.1761e-04 - acc: 1.0000     \nEpoch 109/150\n875/875 [==============================] - 0s - loss: 1.8029e-04 - acc: 1.0000     \nEpoch 110/150\n875/875 [==============================] - 0s - loss: 1.6070e-04 - acc: 1.0000     \nEpoch 111/150\n875/875 [==============================] - 0s - loss: 1.6345e-04 - acc: 1.0000     \nEpoch 112/150\n875/875 [==============================] - 0s - loss: 1.5899e-04 - acc: 1.0000     \nEpoch 113/150\n875/875 [==============================] - 0s - loss: 1.4139e-04 - acc: 1.0000     \nEpoch 114/150\n875/875 [==============================] - 0s - loss: 1.3230e-04 - acc: 1.0000     \nEpoch 115/150\n875/875 [==============================] - 0s - loss: 1.2006e-04 - acc: 1.0000     \nEpoch 116/150\n875/875 [==============================] - 0s - loss: 1.2011e-04 - acc: 1.0000     \nEpoch 117/150\n875/875 [==============================] - 0s - loss: 1.1374e-04 - acc: 1.0000     \nEpoch 118/150\n875/875 [==============================] - 0s - loss: 1.1999e-04 - acc: 1.0000     \nEpoch 119/150\n875/875 [==============================] - 0s - loss: 1.0095e-04 - acc: 1.0000     \nEpoch 120/150\n875/875 [==============================] - 0s - loss: 9.8372e-05 - acc: 1.0000     \nEpoch 121/150\n875/875 [==============================] - 0s - loss: 9.3190e-05 - acc: 1.0000     \nEpoch 122/150\n875/875 [==============================] - 0s - loss: 9.1499e-05 - acc: 1.0000     \nEpoch 123/150\n875/875 [==============================] - 0s - loss: 7.8799e-05 - acc: 1.0000     \nEpoch 124/150\n875/875 [==============================] - 0s - loss: 7.8211e-05 - acc: 1.0000     \nEpoch 125/150\n875/875 [==============================] - 0s - loss: 8.1663e-05 - acc: 1.0000     \nEpoch 126/150\n875/875 [==============================] - 0s - loss: 7.7535e-05 - acc: 1.0000     \nEpoch 127/150\n875/875 [==============================] - 0s - loss: 7.1393e-05 - acc: 1.0000     \nEpoch 128/150\n875/875 [==============================] - 0s - loss: 7.3230e-05 - acc: 1.0000     \nEpoch 129/150\n875/875 [==============================] - 0s - loss: 6.2437e-05 - acc: 1.0000     \nEpoch 130/150\n875/875 [==============================] - 0s - loss: 5.6658e-05 - acc: 1.0000     \nEpoch 131/150\n875/875 [==============================] - 0s - loss: 5.4947e-05 - acc: 1.0000     \nEpoch 132/150\n875/875 [==============================] - 0s - loss: 4.9836e-05 - acc: 1.0000     \nEpoch 133/150\n875/875 [==============================] - 0s - loss: 5.1671e-05 - acc: 1.0000     \nEpoch 134/150\n875/875 [==============================] - 0s - loss: 4.6462e-05 - acc: 1.0000     \nEpoch 135/150\n875/875 [==============================] - 0s - loss: 4.5665e-05 - acc: 1.0000     \nEpoch 136/150\n875/875 [==============================] - 0s - loss: 4.2244e-05 - acc: 1.0000     \nEpoch 137/150\n875/875 [==============================] - 0s - loss: 3.9609e-05 - acc: 1.0000     \nEpoch 138/150\n875/875 [==============================] - 0s - loss: 3.6748e-05 - acc: 1.0000     \nEpoch 139/150\n875/875 [==============================] - 0s - loss: 3.7038e-05 - acc: 1.0000     \nEpoch 140/150\n875/875 [==============================] - 0s - loss: 3.5933e-05 - acc: 1.0000     \nEpoch 141/150\n875/875 [==============================] - 0s - loss: 3.7376e-05 - acc: 1.0000     \nEpoch 142/150\n875/875 [==============================] - 0s - loss: 3.0436e-05 - acc: 1.0000     \nEpoch 143/150\n875/875 [==============================] - 0s - loss: 2.9973e-05 - acc: 1.0000     \nEpoch 144/150\n875/875 [==============================] - 0s - loss: 2.8622e-05 - acc: 1.0000     \nEpoch 145/150\n875/875 [==============================] - 0s - loss: 2.6297e-05 - acc: 1.0000     \nEpoch 146/150\n875/875 [==============================] - 0s - loss: 2.7446e-05 - acc: 1.0000     \nEpoch 147/150\n875/875 [==============================] - 0s - loss: 2.4153e-05 - acc: 1.0000     \nEpoch 148/150\n875/875 [==============================] - 0s - loss: 2.3199e-05 - acc: 1.0000     \nEpoch 149/150\n875/875 [==============================] - 0s - loss: 2.1933e-05 - acc: 1.0000     \nEpoch 150/150\n875/875 [==============================] - 0s - loss: 2.0953e-05 - acc: 1.0000     \n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7fcd41ede438>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# evaluate the model\nscores = model.evaluate(X_scale_test, y_test)\nprint(\"Evaluation with Test data:\")\nprint(\"{0}: {1:.4f}\".format(model.metrics_names[1].upper(), scores[1]*100))",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": " 32/375 [=>............................] - ETA: 0sEvaluation with Test data:\nACC: 98.4000\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from keras import metrics",
      "execution_count": 1,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}