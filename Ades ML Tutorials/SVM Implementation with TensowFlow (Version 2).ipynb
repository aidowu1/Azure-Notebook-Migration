{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SVM Implementation with TensowFlow\n",
    " - Reference: This work is based on material provided in the book: TensorFlow Machine Learning Cookbook by Nick McClure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.datasets import (load_breast_cancer, load_iris)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProblemProvider(object):\n",
    "    def __init__(self):\n",
    "        self._problem_store = {}\n",
    "        self._X_train, self._X_test, self._y_train, self._y_test = None, None, None, None\n",
    "        self._scaled_X_train, self._scaled_X_test = None, None\n",
    "        self.setProblemData()\n",
    "            \n",
    "    def setCancerData(self):\n",
    "        cancer_data = load_breast_cancer()\n",
    "        X = cancer_data.data\n",
    "        y = cancer_data.target\n",
    "        y = np.array([-1 if y == 0 else 1 for y in y])\n",
    "        y = np.reshape(y, (y.shape[0], 1))\n",
    "        self._X_train, self._X_test, self._y_train, self._y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "        self.rescaleData()\n",
    "        \n",
    "    def setIrisData(self):\n",
    "        iris_data = load_iris()\n",
    "        X = np.array([[x[0], x[3]] for x in iris_data.data])\n",
    "        y = np.array([1 if y == 0 else -1 for y in iris_data.target])\n",
    "        #y = np.reshape(y, (y.shape[0], 1))\n",
    "        self._X_train, self._X_test, self._y_train, self._y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "        self.rescaleData()\n",
    "        \n",
    "    def setProblemData(self):\n",
    "        data_sets = {'Cancer_Data': self.setCancerData, 'Iris_Data': self.setIrisData}\n",
    "        for data_set in data_sets:\n",
    "            data_sets[data_set]()\n",
    "            self._problem_store[data_set] = {\n",
    "                                    'Scaler': self._scaler,\n",
    "                                    'X_train_scaled':  self._X_train_scaled,\n",
    "                                    \"X_test_scaled\": self._X_test_scaled,\n",
    "                                    \"y_train\": self._y_train,\n",
    "                                    \"y_test\": self._y_test\n",
    "                                        }\n",
    "\n",
    "    def rescaleData(self):\n",
    "        self._scaler = StandardScaler()\n",
    "        self._X_train_scaled = self._scaler.fit_transform(self._X_train)\n",
    "        self._X_test_scaled = self._scaler.fit_transform(self._X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_provider = ProblemProvider()\n",
    "cancer_problem_prov = problem_provider._problem_store['Iris_Data']\n",
    "scaler = cancer_problem_prov['Scaler']\n",
    "X_train = cancer_problem_prov['X_train_scaled']\n",
    "X_test = cancer_problem_prov['X_test_scaled']\n",
    "y_train = cancer_problem_prov['y_train']\n",
    "y_test = cancer_problem_prov['y_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.47393679, -1.30948358],\n",
       "       [-0.13307079, -1.04292204],\n",
       "       [ 1.08589829,  0.28988568],\n",
       "       [-1.23014297, -1.30948358],\n",
       "       [-1.7177306 , -1.30948358]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the SVM using Tensorflow constructs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SvmUsingTensorflow(object):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        # Define the Tensorflow session\n",
    "        ops.reset_default_graph()\n",
    "        self._sess = tf.Session()\n",
    "        \n",
    "        # Define number of iteration to start reporting updates\n",
    "        self._reported_iteration = 100\n",
    "        \n",
    "        # Define the training feature dataset\n",
    "        self._X_train = X_train\n",
    "        \n",
    "        # Define the training target vector\n",
    "        self._y_train = y_train\n",
    "        \n",
    "        # Define the number of training samples/features\n",
    "        self._n_samples = self._X_train.shape[0]\n",
    "        self._n_features = float(self._X_train.shape[1])\n",
    "        \n",
    "        # Declare batch size\n",
    "        self._batch_size = 50\n",
    "        \n",
    "        # Declare the Guassain Kernel 'gamma' parameter\n",
    "        self._gamma_param = -25.\n",
    "        \n",
    "        # Define learning rate\n",
    "        self._learn_rate = 0.01\n",
    "\n",
    "        # Initialize placeholders\n",
    "        self._x_data = tf.placeholder(shape=[None, self._n_features], dtype=tf.float32)\n",
    "        self._y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "        self._prediction_grid = tf.placeholder(shape=[None, self._n_features], dtype=tf.float32)\n",
    "        \n",
    "        # Create variables for svm\n",
    "        self._b = tf.Variable(tf.random_normal(shape=[1, self._batch_size]))\n",
    "        \n",
    "        # Define the feature/prediction kernelss\n",
    "        self._feature_kernel = self.computeGuassainFeatureKernel()\n",
    "        self._predict_kernel = self.computeGuassainPredictionKernel()\n",
    "        \n",
    "        # Define the loss function\n",
    "        self._loss = self.computeLoss()\n",
    "        \n",
    "        # Define the model Accuracy\n",
    "        self._accuracy = self.computeAccuracy()\n",
    "        \n",
    "        # Define the Trainer\n",
    "        self._train_step = self.computeTrainer()\n",
    "        \n",
    "        # Initialize variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        self._sess.run(init)\n",
    "        \n",
    "    \n",
    "    def computeLinearFeatureKernel(self):\n",
    "        sq_dists = tf.matmul(self._x_data, tf.transpose(self._x_data))\n",
    "        return sq_dists    \n",
    "    \n",
    "    def computeGuassainFeatureKernel(self):\n",
    "        gamma = tf.constant(self._gamma_param)\n",
    "        sq_dists = tf.multiply(self._n_features, tf.matmul(self._x_data, tf.transpose(self._x_data)))\n",
    "        return tf.exp(tf.multiply(gamma, tf.abs(sq_dists)))\n",
    "    \n",
    "    def computeLinearPredictionKernel(self):\n",
    "        sq_dists = tf.matmul(self._x_data, tf.transpose(self._prediction_grid))\n",
    "        return sq_dists    \n",
    "    \n",
    "    def computeGuassainPredictionKernel(self):\n",
    "        gamma = tf.constant(self._gamma_param)\n",
    "        rA = tf.reshape(tf.reduce_sum(tf.square(self._x_data), 1), [-1, 1])\n",
    "        rB = tf.reshape(tf.reduce_sum(tf.square(self._prediction_grid), 1), [-1, 1])\n",
    "        pred_sq_dist = tf.add(tf.subtract(rA, tf.multiply(\n",
    "            self._n_features, tf.matmul(self._x_data, tf.transpose(self._prediction_grid)))), tf.transpose(rB))\n",
    "        pred_kernel = tf.exp(tf.multiply(gamma, tf.abs(pred_sq_dist)))\n",
    "        return pred_kernel\n",
    "        \n",
    "    def computeLoss(self):        \n",
    "        first_term = tf.reduce_sum(self._b)\n",
    "        b_vec_cross = tf.matmul(tf.transpose(self._b), self._b)\n",
    "        y_target_cross = tf.matmul(self._y_target, tf.transpose(self._y_target))\n",
    "        second_term = tf.reduce_sum(tf.multiply(self._feature_kernel, tf.multiply(b_vec_cross, y_target_cross)))\n",
    "        loss = tf.negative(tf.subtract(first_term, second_term))\n",
    "        return loss\n",
    "    \n",
    "    def computeAccuracy(self):\n",
    "        prediction_output = tf.matmul(tf.multiply(tf.transpose(self._y_target), self._b), self._predict_kernel)\n",
    "        prediction = tf.sign(prediction_output - tf.reduce_mean(prediction_output))\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.squeeze(prediction), tf.squeeze(self._y_target)), tf.float32))\n",
    "        return accuracy\n",
    "    \n",
    "    def computeTrainer(self):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(self._learn_rate)\n",
    "        train_step = optimizer.minimize(self._loss)\n",
    "        return train_step\n",
    "        \n",
    "    def updateStatus(self, i, loss_i, accuracy_i):\n",
    "        if (i + 1) % self._reported_iteration == 0:\n",
    "            print('Step: #{0}\\tLoss: {1:.4f}\\tAccuracy: {2:.4f}'.format(i + 1, loss_i, accuracy_i))            \n",
    "        \n",
    "    def runMainLoop(self, epochs=300):\n",
    "        loss_vec = []\n",
    "        batch_accuracy = []\n",
    "        for i in range(epochs):\n",
    "            rand_index = np.random.choice(len(self._X_train), size=self._batch_size)\n",
    "            rand_x = self._X_train[rand_index]\n",
    "            rand_y = np.transpose([self._y_train[rand_index]])\n",
    "            self._sess.run(self._train_step, feed_dict={self._x_data: rand_x, self._y_target: rand_y})\n",
    "            loss_i = self._sess.run(self._loss, feed_dict={self._x_data: rand_x, self._y_target: rand_y})\n",
    "            loss_vec.append(loss_i)\n",
    "            accuracy_i = self._sess.run(self._accuracy, feed_dict={self._x_data: rand_x,\n",
    "                                                     self._y_target: rand_y,\n",
    "                                                     self._prediction_grid: rand_x})\n",
    "            batch_accuracy.append(accuracy_i)\n",
    "            self.updateStatus(i, loss_i, accuracy_i)\n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: #100\tLoss: -6.2352\tAccuracy: 0.8400\n",
      "Step: #200\tLoss: -16.4429\tAccuracy: 0.9400\n",
      "Step: #300\tLoss: -19.8027\tAccuracy: 0.9000\n",
      "Step: #400\tLoss: -33.8937\tAccuracy: 0.9800\n",
      "Step: #500\tLoss: -39.7540\tAccuracy: 0.9800\n",
      "Step: #600\tLoss: -34.6916\tAccuracy: 0.9600\n",
      "Step: #700\tLoss: -16.9913\tAccuracy: 0.9400\n",
      "Step: #800\tLoss: -51.1725\tAccuracy: 0.9200\n",
      "Step: #900\tLoss: -58.3918\tAccuracy: 0.8800\n",
      "Step: #1000\tLoss: -27.4812\tAccuracy: 0.7800\n"
     ]
    }
   ],
   "source": [
    "def runIrisClassifyProblem():\n",
    "    problem_provider = ProblemProvider()\n",
    "    iris_problem_prov = problem_provider._problem_store['Cancer_Data']\n",
    "    scaler = cancer_problem_prov['Scaler']\n",
    "    X_train = cancer_problem_prov['X_train_scaled']\n",
    "    X_test = cancer_problem_prov['X_test_scaled']\n",
    "    y_train = cancer_problem_prov['y_train']\n",
    "    y_test = cancer_problem_prov['y_test']\n",
    "#     iris_data = load_iris()\n",
    "#     X_train = np.array([[x[0], x[3]] for x in iris_data.data])\n",
    "#     y_train = np.array([1 if y == 0 else -1 for y in iris_data.target])\n",
    "#     print(\"y_train.shape:{}\".format(y_train.shape))\n",
    "    svm_model = SvmUsingTensorflow(X_train=X_train, y_train=y_train)\n",
    "    svm_model.runMainLoop(1000)\n",
    "\n",
    "runIrisClassifyProblem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
