{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Credit Card Default Problem\n - Predicting Credit Card Default Payment Problem\n - Data will be based on open source customer defauly payments data in Taiwan for a period in 2005\n - Data can be sourced from UCI [here](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients#)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Problem specification\n\n**<mark>Introduction</mark>**\n\nOver the years millions of adults all over the world default on thier credit card monthly payments.\nIn recent times, in order to gain maximum market share, banks have over-issued credit cards to borrowers with suspect credit ratings/history. The problem is further exacerbate due to availiability of cheap credit and card holders overuse of their credit cards for consumption irrespective of their debt repayment ability. \nIn this exercise an ensemble of Machine Learing (ML) models are going to be used to predict this credit default risk. There have been a number of studies in the past to develop predictive analytic models of this type. One such study can be found in the seminal paper by [Yeh, I. C., and Lien, C. H.](https://bradzzz.gitbooks.io/ga-seattle-dsi/content/dsi/dsi_05_classification_databases/2.1-lesson/assets/datasets/DefaultCreditCardClients_yeh_2009.pdf). Typical such models use financial information such as client transaction data, demographic data, repayment details etc to predict the credit card holder risk of default.\n\nIn this study, I will be using Taiwan credit card data provided by Yeh, I. C., and Lien, C. H. that can be sourced from the UCI [location](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients#). This data consist of 30,000 samples and is made up of 23 independent variables with the dependent variable being the measure of default payment for the next month.\n\n---\n\n**<mark>References</mark>**\n- \"Feature Enginerring Made Easy\" by Sinan Ozdemir and Divya Susarla (Chapter 5)\n- Jason Brownlee's ML blog located [here](https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/)\n\n\n\n\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Approach Steps\n\n- Read Data\n- Data Cleaning:\n    * Check for missing data and correct with data Imputation\n    * Rename columns where necessary\n- Exporatory Data Analysis:\n    * Descriptive Statistics\n    * Check feature data types\n    * Identify features which are continious (Numeric)\n    * Identify features which are categorical (Discrete/Nominal)\n    * Measure class imbalance\n    * Measure correlation  between the features\n    * Measure skewness of univariate distributions\n- Feature Preprocessing:\n    * Convert categorical to numeric data (using [one-hot](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) label-encoding encoding for cases when the feature has more than 2 unique values)\n    * Convert categorical to numeric data (using [label](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder) encoding when the categorical variable consists of only 2 unique values)\n    * Normalize or re-scale the numeric features within a suitable range such as (0-1) using [MinMaxScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler) or [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) from Scikit Learn\n    * Resolve any data imbalancing issues using re-sampling (over-sampling/under-sample) techniques such as SMOTE - Synthetic Minority Oversampling TEchnique. A python library for doing this can be found [here](http://contrib.scikit-learn.org/imbalanced-learn/stable/install.html) \n- Feature Selection and Dimensionality Reduction\n    * Use the Pearson correlation metrics (including heatmap) to find the features highly correlated with the response (label)\n    * Use Hypothesis testing using Scikit Learn's [SelectKBest](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)\n    * Use Recursive Feature Elimination using Scikit Learn's [RFE](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)\n    * Use Principal Component Analysis [PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) to remove redundant data \n- Specify the classification Models:\n    * K-Nearest Neighbor [KNN](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n    * Naive Bayes [GaussianNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n    * Decesion Tree [DecisionTreeClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n    * Random Forest [RandomForestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n    * Support Vector Machines [svm](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n    * Quadratic Discriminant Analysis [QuadraticDiscriminantAnalysis](http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis)\n    * Deep MLP (Muti Layer Perceptron) Neural Net [KerasClassifier](https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/)\n- Evaluation of the Classification Models:\n    * Stratified K-fold Cross validation [StratifiedKFold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html)\n    * Receiver Operating Characteristics (ROC) curves evaluation [roc_curve](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve)\n    * Area Under Curve of ROC evaluation [auc](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html#sklearn.metrics.auc)\n    * Precision and Recall Curves [precision_recall_curve](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html)\n    * Confusion Matrix [evaluation](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) and [plot](http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py) "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Define imports"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport os\nimport pprint\nimport matplotlib.pylab as pl",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Read Credit Card Default data and define global variables"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "SEED = 10\nDATA_FILE_PATH_XLS = './data/default of credit card clients.xls'\nDATA_FILE_PATH_CSV = './data/default_of_credit_card_clients.csv'\nRAW_CREDIT_DATA_RAW = pd.read_excel(DATA_FILE_PATH_XLS, sheet = 0, skiprows= 1, header = 0)\nRAW_CREDIT_DATA_RAW.to_csv(DATA_FILE_PATH_CSV)\nRAW_CREDIT_DATA = pd.read_csv(DATA_FILE_PATH_CSV, index_col=0)\nN_FEATURES = len(RAW_CREDIT_DATA.columns) - 1\nN_SAMPLES = RAW_CREDIT_DATA.shape[0]\nDEPENDENT_VARIABLE = 'default payment next month'\nINDEPENDENT_VARIABLES = list(set(RAW_CREDIT_DATA.columns) - set([DEPENDENT_VARIABLE]))\nN_RESPONSES = 1\nSPLIT_FRACTION = 0.30\nCV = 5",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Exploratory Data Analysis"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pp = pprint.PrettyPrinter(indent=4)\ndef basicExploratoryDataFacts():\n    \"\"\"\n    \"\"\"\n    print(\"Number of (independent) features: {}\".format(N_FEATURES))\n    print(\"Number of samples/observations: {}\".format(N_SAMPLES))\n    print(\"Label/Dependent attribute: '{}'\".format(DEPENDENT_VARIABLE))\n    print(\"Features are:\")\n    pp.pprint(INDEPENDENT_VARIABLES)\n\ndef getIndependentAndDependentVariables():\n    \"\"\"\n    Extraxt the Indpendent/depend variables from the problem data\n    \"\"\"\n    # Create our feature matrix\n    X = RAW_CREDIT_DATA.drop(DEPENDENT_VARIABLE, axis=1)\n    # create our response variable\n    y = RAW_CREDIT_DATA[DEPENDENT_VARIABLE]\n    return (X, y)",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "basicExploratoryDataFacts()\nX, y = getIndependentAndDependentVariables()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Number of (independent) features: 24\nNumber of samples/observations: 30000\nLabel/Dependent attribute: 'default payment next month'\nFeatures are:\n[   'AGE',\n    'SEX',\n    'PAY_6',\n    'PAY_4',\n    'PAY_5',\n    'PAY_2',\n    'PAY_3',\n    'PAY_0',\n    'BILL_AMT5',\n    'BILL_AMT4',\n    'BILL_AMT6',\n    'LIMIT_BAL',\n    'BILL_AMT3',\n    'BILL_AMT2',\n    'ID',\n    'PAY_AMT6',\n    'PAY_AMT5',\n    'PAY_AMT4',\n    'PAY_AMT3',\n    'PAY_AMT2',\n    'PAY_AMT1',\n    'BILL_AMT1',\n    'MARRIAGE',\n    'EDUCATION']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Classification Models\n- Define the imports for the models\n- Define a MLP Neural Net classifier model\n- Define other classifier models\n- Define the evaluation of the models"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Imports for the Classifier models"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import (train_test_split, StratifiedKFold, cross_val_score, GridSearchCV)\nfrom sklearn.preprocessing import (LabelEncoder, StandardScaler, MinMaxScaler)\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import (confusion_matrix, accuracy_score)\nimport keras.models as km\nimport keras.layers as kl\nfrom keras.regularizers import l2\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom tensorflow import set_random_seed\n%matplotlib inline",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda2_501/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n  from numpy.core.umath_tests import inner1d\n/home/nbuser/anaconda2_501/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Create MLP Model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def createMlpModel(\n    num_inputs=N_FEATURES,\n    num_ouputs=N_RESPONSES,\n    input_nodes = 10, \n    hidden_act='relu', \n    output_act='sigmoid',\n    hidden_nodes = 10,\n    optimizer='rmsprop', \n    init='glorot_uniform'):\n    '''\n    Create a MLP model using Keras\n    '''\n    model = km.Sequential()\n    model.add(kl.Dense(input_nodes, input_dim=num_inputs, activation=hidden_act,kernel_initializer=init))\n    model.add(kl.Dense(hidden_nodes, activation=hidden_act,kernel_initializer=init))\n    model.add(kl.Dense(1, activation=output_act,kernel_initializer=init))\n    # Compile model\n    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    return model",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Define other Classifier models"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from collections import OrderedDict\ndef createMlpParams():\n    \"\"\"\n    Creates a dictionary of MLP params\n    \"\"\"\n    optimizers = ['rmsprop', 'adam']\n    init = ['glorot_uniform', 'normal', 'uniform']\n    epochs = [50, 100, 150]\n    batches = [5, 10, 20]\n    param_dict = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=init)\n    return param_dict\n\ndef createModelParams():\n    \"\"\"\n    Creates a dictionary of Model Parameters\n    \"\"\"\n    model_params = {}\n    # Logistic Regression\n    lr_params = {'C':[1e-1, 1e0, 1e1, 1e2], 'penalty':['l1', 'l2']}\n    model_params['Logistic'] = lr_params\n\n    # Random Forest\n    forest_params = {'n_estimators': [10, 50, 100], 'max_depth': [None, 1, 3, 5, 7]}\n    model_params['RFC'] = forest_params\n    \n    # SVM\n    svm_params = {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf', 'linear']}\n    model_params['SVM'] = svm_params\n                  \n    # QDA\n    qda_params = {'reg_param':[0, 1e-1, 1e-2, 1e0, 1e1], 'tol':[1e-4, 1e-5]}\n    model_params['QDA'] = qda_params\n    \n    # KNN\n    knn_params = {'n_neighbors': [1, 3, 5, 7]}\n    knn_pipe_params = {'classifier__{}'.format(k): v for k, v in knn_params.iteritems()}\n    model_params['KNN'] = knn_pipe_params\n    \n    # MLP\n    mlp_params = createMlpParams()\n    mlp_pipe_params = {'classifier__{}'.format(k): v for k, v in mlp_params.iteritems()}\n    model_params['MLP'] = mlp_pipe_params\n    return model_params\n        \n    \ndef createAllModels():\n    \"\"\"\n    Creates a dictionary of classification models\n    \"\"\"\n    clf1 = LogisticRegression(random_state=0)\n    clf2 = RandomForestClassifier(random_state=0)\n    clf3 = SVC(random_state=0, probability=True)\n    clf4 = QuadraticDiscriminantAnalysis()\n    knn = KNeighborsClassifier()\n    clf5 = Pipeline([('scale', StandardScaler()), ('classifier', knn)])    \n    mlp = KerasClassifier(build_fn=createMlpModel, epochs=150, batch_size=10, verbose=0)\n    clf6 = knn_pipe = Pipeline([('scale', StandardScaler()), ('classifier', mlp)])\n    classifiers = [('Logistic', clf1), ('RFC', clf2), ('SVM', clf3), ('QDA', clf4), ('KNN', clf5), ('MLP', clf6)]    \n    models = OrderedDict(classifiers)\n    return models\n\ndef createAllModelsAndParams(models, params):\n    \"\"\"\n    Returns a dictionary of all the models/params\n    \"\"\"\n    models_and_params = {key:(params[key], models[key]) for key in models}\n    return models_and_params\n\n# def countNumberOfCalculations(params):\n#     \"\"\"\n#     Returns/computes the number of calculations for all the grid searched models/params\n#     \"\"\"\n#     count = 0\n#     for key in params:\n#         model_param = params[key]\n#         for key2 in model_param:\n#             model_param_list = model_param[key2]\n#             count += len(model_param_list)\n            \n        \n    return models_and_params\n\ndef createEnsembleVotingModel(optimal_models):\n    \"\"\"\n    \"\"\"\n    eclf = VotingClassifier(estimators=optimal_models.values, weights=[2, 1, 1, 1, 1, 2], voting='soft')\n    return eclf\n    \n\ndef evaluateBestModels(models_and_params, X, y, cv=CV):\n    \"\"\"\n    Evaluates the model using a search grid approach\n    \"\"\"\n    best_models = {}\n    model_names = []\n    model_accuracy = []\n    model_best_params = []\n    model_avg_fit_time = []\n    model_avg_score_time = []\n    total_count = len(list(models_and_params.keys()))\n    curr_count = 0.0\n    for model_name, model_and_param in models_and_params.iteritems():\n        curr_count += 1\n        per_progress = 100.0*(float(curr_count)/float(total_count))\n        params = model_and_param[0]\n        model = model_and_param[1]         \n        grid = GridSearchCV(model, # the model to grid search\n                        params, # the parameter set to try \n                        error_score=0., n_jobs = -1) # if a parameter set raises an error, continue and set the performance as a big, fat 0\n        grid.fit(X, y) # fit the model and parameters\n        best_models[model_name] = grid\n        model_accuracy.append(\"{}\".format(grid.best_score_))\n        model_best_params.append(\"{}\".format(grid.best_params_))\n        model_avg_fit_time.append(\"{}\".format(round(grid.cv_results_['mean_fit_time'].mean(), 3)))\n        model_avg_score_time.append(\"{}\".format(round(grid.cv_results_['mean_score_time'].mean(), 3)))\n        print(\"Current processing model: {0} and the progress is: {1} \".format(model_name,per_progress))\n    results = {\n        'Model Names': model_names,\n        'Best Accuracy':model_accuracy,\n        'Best Params': model_best_params,\n        'Avg Fit Time':model_avg_fit_time,\n        'Avg Score Time':model_avg_score_time\n    }\n    results_table = pd.DataFrame(results)\n    return best_models, results_table\n    ",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model_params = createModelParams()\nmodels = createAllModels()\nmodels_and_params = createAllModelsAndParams(models, model_params)\nbest_models, results_table = evaluateBestModels(models_and_params, X, y) ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Current processing model: KNN and the progress is: 16.6666666667 \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "l = [(1,2), (1,4)]\nl.append((1,3))\nl1, l2 = zip(*l)\nprint(\"l1 = {0}\\nl2 = {1}\".format(l1, l2))",
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "l1 = (1, 1, 1)\nl2 = (2, 4, 3)\n"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x = {'A': range(10), 'B':range(10,100,10)}\nfor key, value in x.iteritems():\n    print(key, value)",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "('A', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n('B', [10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}