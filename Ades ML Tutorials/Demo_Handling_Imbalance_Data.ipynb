{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Demo Handling of Imbalance Data For Classification Problems\n",
    "- Demos the use of SMOTE - Synthetic Minority Oversampling TEchnique for resolving a data imbalance problem\n",
    "- The demo uses the [imblearn api](http://contrib.scikit-learn.org/imbalanced-learn/stable/generated/imblearn.over_sampling.SMOTE.html)\n",
    "- Also I refer to the [Nick Becker's blog](https://beckernick.github.io/oversampling-modeling/) which explains the correct way to apply oversampling to correct data imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing imbalanced-learn\n",
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/a4/900463a3c0af082aed9c5a43f4ec317a9469710c5ef80496c9abc26ed0ca/imbalanced_learn-0.3.3-py3-none-any.whl (144kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 8.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement not upgraded as not directly required: scikit-learn in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from imbalanced-learn) (0.19.1)\n",
      "Requirement not upgraded as not directly required: scipy in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from imbalanced-learn) (0.19.1)\n",
      "Requirement not upgraded as not directly required: numpy in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from imbalanced-learn) (1.14.3)\n",
      "\u001b[31mgrpcio 1.11.0 has requirement protobuf>=3.5.0.post1, but you'll have protobuf 3.4.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preg</th>\n",
       "      <th>glucose_conc</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diab_pred</th>\n",
       "      <th>age</th>\n",
       "      <th>skin</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1.3790</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>1.1426</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  diab_pred  \\\n",
       "0         6           148            72         35        0  33.6      0.627   \n",
       "1         1            85            66         29        0  26.6      0.351   \n",
       "2         8           183            64          0        0  23.3      0.672   \n",
       "\n",
       "   age    skin  diabetes  \n",
       "0   50  1.3790      True  \n",
       "1   31  1.1426     False  \n",
       "2   32  0.0000      True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 10\n",
    "data_path = './data/pima-data.csv'\n",
    "# Loading some example data\n",
    "raw_data = pd.read_csv(data_path, delimiter=',')\n",
    "data = raw_data.values\n",
    "X, y = data[:,0:9], data[:,-1]\n",
    "N_SAMPLES = X.shape[0]\n",
    "N_FEATURES = X.shape[1]\n",
    "N_RESPONSES = 1\n",
    "SPLIT_FRACTION = 0.30\n",
    "CV = 5\n",
    "raw_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Label y to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y_encoded = encoder.transform(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the label imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65.10416666666666, 34.89583333333333)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeImbalance(y):\n",
    "    label_imbalance = (np.count_nonzero(y==0)/y.shape[0])*100, (np.count_nonzero(y==1)/y.shape[0])*100\n",
    "    return label_imbalance\n",
    "\n",
    "computeImbalance(y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into Training and Test partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training data to get the Validation partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, X_valid, y_train_new, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply SMOTE Oversampling to the Training Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=SEED, ratio = 'minority')\n",
    "X_train_resample, y_train_resample = sm.fit_sample(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the Class Imbalance on the Training set after SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance \n",
      "\n",
      "Before Oversampling:\n",
      "(63.929146537842186, 36.07085346215781)\n",
      "\n",
      "After Oversampling:\n",
      "(50.0, 50.0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Class imbalance \\n\\nBefore Oversampling:\\n{0}\\n\\nAfter Oversampling:\\n{1}\".format(computeImbalance(y_train_new), computeImbalance(y_train_resample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Random Forest Classifier Model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=25, random_state=SEED)\n",
    "clf_rf.fit(X_train_resample, y_train_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalaute the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Score: 0.8142857142857143\n",
      "Recall: 0.7777777777777778\n",
      "\n",
      "Test Results\n",
      "Score: 0.7142857142857143\n",
      "Recall: 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "def printEvaluationReport(model, data):\n",
    "    X_valid, X_test, y_valid, y_test = data\n",
    "    print('Validation Results')\n",
    "    print(\"Score: {}\".format(model.score(X_valid, y_valid)))\n",
    "    print(\"Recall: {}\".format(recall_score(y_valid, clf_rf.predict(X_valid))))\n",
    "    print('\\nTest Results')\n",
    "    print(\"Score: {}\".format(model.score(X_test, y_test)))\n",
    "    print(\"Recall: {}\".format(recall_score(y_test, clf_rf.predict(X_test))))\n",
    "\n",
    "data = (X_valid, X_test, y_valid, y_test)\n",
    "printEvaluationReport(clf_rf, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Cross Validation with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 344 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1094 tasks      | elapsed:   58.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2344 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4094 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6344 tasks      | elapsed:  5.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7786 using {'classifier__criterion': 'gini', 'classifier__max_depth': 6, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 100, 'classifier__n_estimators': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed:  6.1min finished\n"
     ]
    }
   ],
   "source": [
    "#X_train_resample2, y_train_resample2 = sm.fit_sample(X_train, y_train)\n",
    "rf_class_weight = [{0:0.01, 1:0.99}, {0:0.10, 1:0.90}, {0:0.80, 1:0.20}]\n",
    "parameters = {'classifier__n_estimators':range(10, 100, 10),\n",
    "             'classifier__max_features':['sqrt', 'log2'],\n",
    "             'classifier__max_depth': range(1, 50, 5),\n",
    "             'classifier__min_samples_split': [100, 200],\n",
    "             'classifier__min_samples_leaf': [5, 10],\n",
    "             'classifier__criterion': ['entropy', 'gini']}\n",
    "rf_cv = RandomForestClassifier(random_state=SEED)\n",
    "model = Pipeline([\n",
    "        ('sampling', sm),\n",
    "        ('classifier', rf_cv)\n",
    "    ])\n",
    "clf_grid_search = GridSearchCV(model, parameters, cv=CV,verbose=True, n_jobs=-1)\n",
    "clf_grid_search.fit(X_train, y_train)\n",
    "print(\"Best: {0:.4f} using {1}\".format(clf_grid_search.best_score_, str(clf_grid_search.best_params_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the trained CV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Score: 0.808972503617945\n",
      "Recall: 0.9834710743801653\n",
      "\n",
      "Test Results\n",
      "Score: 0.7402597402597403\n",
      "Recall: 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "data = (X_train, X_test, y_train, y_test)\n",
    "printEvaluationReport(clf_grid_search, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
