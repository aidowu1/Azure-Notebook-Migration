{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering graph using document based clustering approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Corpus data from disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_folder = r\"C:\\Titan\\Data\\PartitionServiceData\"\n",
    "data_file = r\"\\RUSH_05Oct2017_TopLevelTradeDependency_16Nov2017.csv\"\n",
    "#file_path = os.path.join(path_folder, data_file)\n",
    "file_path = r\"C:\\Titan\\Data\\PartitionServiceData\\RUSH_05Oct2017_TopLevelTradeDependency_16Nov2017.csv\"\n",
    "def createCorpus(file_path):\n",
    "    corpus = []\n",
    "    with open(file_path, 'rb') as csv_file:\n",
    "        data = csv.reader(csv_file, delimiter='|')\n",
    "        for row in data:\n",
    "            row1 = [string.replace(s, ',', '_') for s in row]\n",
    "            row2 = [string.replace(s, ' ', '_') for s in row1]\n",
    "            document = ' '.join(row2) \n",
    "            corpus.append(document)\n",
    "            #print(row2)\n",
    "        print('corpus: {}'.format(corpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"discountCurve_USD, Funding, Time_1, Time_2\",\n",
    "            \"discountCurve_EUR, Funding, Time_1, Time_2, bondDefaultCurve\",\n",
    "             \"discountCurve_GBP, Funding, defaultCurve, Time_1, Time_2\",\n",
    "             \"discountCurve_EUR, Funding, Time_1, Time_2, bondDefaultCurve, recovery\",\n",
    "             \"discountCurve_EUR, Funding, Time_1, Time_2, loanDefaultCurve\",\n",
    "             \"discountCurve_USD, Funding, Time_1, Time_2\",\n",
    "            \"discountCurve_EUR, Funding, Time_1, Time_2, bondDefaultCurve\",\n",
    "             \"discountCurve_GBP, Funding, defaultCurve, Time_1, Time_2\",\n",
    "             \"discountCurve_EUR, Funding, Time_1, Time_2, bondDefaultCurve, recovery\",\n",
    "             \"discountCurve_EUR, Funding, Time_1, Time_2, loanDefaultCurve\",\n",
    "            ]\n",
    "#documents = createCorpus(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the corpus data to convert the data from text to numeric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english',lowercase=False)\n",
    "X = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Document Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34738346,  0.34738346,  0.34738346,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.79873287,  0.        ,  0.        ],\n",
       "       [ 0.34696212,  0.34696212,  0.34696212,  0.62052696,  0.        ,\n",
       "         0.50378384,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.2714286 ,  0.2714286 ,  0.2714286 ,  0.        ,  0.62409116,\n",
       "         0.        ,  0.62409116,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.27122747,  0.27122747,  0.27122747,  0.48507876,  0.        ,\n",
       "         0.39381825,  0.        ,  0.        ,  0.        ,  0.6236287 ],\n",
       "       [ 0.31016195,  0.31016195,  0.31016195,  0.        ,  0.        ,\n",
       "         0.45035054,  0.        ,  0.        ,  0.71315011,  0.        ],\n",
       "       [ 0.34738346,  0.34738346,  0.34738346,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.79873287,  0.        ,  0.        ],\n",
       "       [ 0.34696212,  0.34696212,  0.34696212,  0.62052696,  0.        ,\n",
       "         0.50378384,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.2714286 ,  0.2714286 ,  0.2714286 ,  0.        ,  0.62409116,\n",
       "         0.        ,  0.62409116,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.27122747,  0.27122747,  0.27122747,  0.48507876,  0.        ,\n",
       "         0.39381825,  0.        ,  0.        ,  0.        ,  0.6236287 ],\n",
       "       [ 0.31016195,  0.31016195,  0.31016195,  0.        ,  0.        ,\n",
       "         0.45035054,  0.        ,  0.        ,  0.71315011,  0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now cluster the data - using kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=4, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_k = 4\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the computed clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 6, 7, 8, 0, 1, 2, 9, 5, 3],\n",
       "       [3, 5, 7, 8, 9, 0, 1, 2, 4, 6],\n",
       "       [3, 4, 5, 6, 8, 9, 0, 1, 2, 7],\n",
       "       [3, 4, 6, 7, 9, 0, 1, 2, 5, 8]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cluster_centers_.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 5, 2, 1, 0, 9, 7, 6, 4, 3],\n",
       "       [3, 5, 9, 2, 1, 0, 8, 7, 6, 4],\n",
       "       [6, 4, 2, 1, 0, 9, 8, 7, 5, 3],\n",
       "       [7, 2, 1, 0, 9, 8, 6, 5, 4, 3]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cluster_centers_.argsort()[:, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 0, 3, 2, 0, 1, 0, 3], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:  bondDefaultCurve  discountCurve_EUR  Time_2  Time_1  Funding  recovery  loanDefaultCurve  discountCurve_USD  discountCurve_GBP  defaultCurve\n",
      "Cluster 1:  discountCurve_USD  Time_2  Time_1  Funding  recovery  loanDefaultCurve  discountCurve_GBP  discountCurve_EUR  defaultCurve  bondDefaultCurve\n",
      "Cluster 2:  discountCurve_GBP  defaultCurve  Time_2  Time_1  Funding  recovery  loanDefaultCurve  discountCurve_USD  discountCurve_EUR  bondDefaultCurve\n",
      "Cluster 3:  loanDefaultCurve  discountCurve_EUR  Time_2  Time_1  Funding  recovery  discountCurve_USD  discountCurve_GBP  defaultCurve  bondDefaultCurve\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print \"Cluster %d:\" % i,\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print ' %s' % terms[ind],\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def createCorpus():\n",
    "    corpus = []\n",
    "    with open(\"myRawData.dat\", 'rb') as csv_file:\n",
    "        data = csv.reader(csv_file, delimiter='|')\n",
    "        for row in data:\n",
    "            row1 = [string.replace(s, ',', '_') for s in row]\n",
    "            row2 = [string.replace(s, ' ', '_') for s in row1]\n",
    "            document = ' '.join(row2) \n",
    "            corpus.append(document)\n",
    "            #print(row2)\n",
    "        print('corpus: {}'.format(corpus))\n",
    "createCorpus()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
